{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm8Fmfmo40ER",
        "outputId": "cbe6a89a-1386-40a1-a74d-f1068b9253ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "zMd8V34g5iJm"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "path = '../content/drive/MyDrive/Colab Notebooks/opencv_project/archive.zip'\n",
        "zip_object = zipfile.ZipFile(file=path, mode='r')\n",
        "zip_object.extractall('./')\n",
        "zip_object.close()"
      ],
      "metadata": {
        "id": "Fqm9XgGp5iLt"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.preprocessing.image.load_img('/content/train/surprise/Training_8796.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "id": "TVl_ObOq5iOG",
        "outputId": "fa97f110-94b0-42c4-c909-05c6402bb059"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=48x48 at 0x7F113F695F70>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample=tf.keras.preprocessing.image.load_img('/content/train/happy/Training_1206.jpg')\n",
        "np.array(sample).shape"
      ],
      "metadata": {
        "id": "Qu5IRGZa5iQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb5e728-e357-4491-bb9a-427bd9638577"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48, 48, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_generator = ImageDataGenerator(horizontal_flip=True,rescale=1/255)  # Degree range for random rotations\n",
        "                                    #  zoom_range=0.2,  # Float or [lower, upper]. Range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range]\n",
        "                                    #  horizontal_flip=True,  # Randomly flip inputs horizontally\n",
        "                                    #  rescale=1/255)  # Rescaling by 1/255 to normalize"
      ],
      "metadata": {
        "id": "39EKK9B7DXmd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_data_generator.flow_from_directory(directory='/content/train',\n",
        "                                                    target_size=(48, 48),  # Tuple of integers (height, width), defaults to (256, 256)\n",
        "                                                    class_mode='categorical',\n",
        "                                                    batch_size=16,  # Size of the batches of data (default: 32)\n",
        "                                                    shuffle=True,  # Whether to shuffle the data (default: True) If set to False, sorts the data in alphanumeric order\n",
        "                                                    seed=10)"
      ],
      "metadata": {
        "id": "mBWuQT8uDXot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a833e465-22c0-49c3-f30b-1642af6c9a5c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28709 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.classes"
      ],
      "metadata": {
        "id": "w-vm19CGDXtH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd37466-1bd9-4318-f1de-4bf9b0a52f58"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 6, 6, 6], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.class_indices"
      ],
      "metadata": {
        "id": "VdR1pvY-FEgN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c595cc-d8bc-4329-ef02-14fb97f5211b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'angry': 0,\n",
              " 'disgust': 1,\n",
              " 'fear': 2,\n",
              " 'happy': 3,\n",
              " 'neutral': 4,\n",
              " 'sad': 5,\n",
              " 'surprise': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(train_dataset.classes, return_counts=True)"
      ],
      "metadata": {
        "id": "H27jlIRkFEiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f11309-be52-4bec-8d88-c10d84c47f52"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6], dtype=int32),\n",
              " array([3995,  436, 4097, 7215, 4965, 4830, 3171]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "test_dataset = test_generator.flow_from_directory(directory='/content/test',\n",
        "                                                  target_size=(48, 48),\n",
        "                                                  class_mode='categorical',\n",
        "                                                  batch_size=1,\n",
        "                                                  shuffle=True)"
      ],
      "metadata": {
        "id": "n2ShsrgeFEkg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ea160e-f271-40d4-f27b-353aff7587f1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, MaxPooling2D , Conv2D, Flatten, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "EGKF2o7z5iSq"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(np.unique(train_dataset.classes))"
      ],
      "metadata": {
        "id": "i7_LkP05MN1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b65d6e7e-3234-46e0-d928-8686b9c00cc9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(np.unique(train_dataset.classes))\n",
        "num_detectors = 32\n",
        "w, h = np.array(sample).shape[:2]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=num_detectors, kernel_size=3, activation='relu', padding='same', input_shape=(w, h, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=num_detectors, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(2*num_detectors, 3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*num_detectors, 3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(2*2*num_detectors, 3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*2*num_detectors, 3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(2*2*2*num_detectors, 3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*2*2*num_detectors, 3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(2*2*num_detectors, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(2*num_detectors, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "jU3Fbd7K5iVC"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "checkpointer = ModelCheckpoint(filepath='../content/drive/MyDrive/Colab Notebooks/opencv_project/model/face_emotion.hdf5', verbose=0, save_best_only=True)\n",
        "early_stopping = EarlyStopping(patience=5)"
      ],
      "metadata": {
        "id": "dV4iJfRI5iXF"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, epochs=100, validation_data=test_dataset,batch_size=32, validation_steps=8, callbacks=[early_stopping,checkpointer])"
      ],
      "metadata": {
        "id": "x8ZlVCoI5iZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c15313c-2a36-4b86-9435-32bf74e4a0d1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1795/1795 [==============================] - 49s 27ms/step - loss: 1.0385 - accuracy: 0.6167 - val_loss: 0.9738 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "1795/1795 [==============================] - 49s 27ms/step - loss: 1.0228 - accuracy: 0.6247 - val_loss: 1.0508 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "1795/1795 [==============================] - 51s 28ms/step - loss: 1.0076 - accuracy: 0.6263 - val_loss: 1.1337 - val_accuracy: 0.6250\n",
            "Epoch 4/100\n",
            "1795/1795 [==============================] - 48s 27ms/step - loss: 1.0017 - accuracy: 0.6307 - val_loss: 1.0261 - val_accuracy: 0.6250\n",
            "Epoch 5/100\n",
            "1795/1795 [==============================] - 50s 28ms/step - loss: 0.9883 - accuracy: 0.6385 - val_loss: 1.0436 - val_accuracy: 0.6250\n",
            "Epoch 6/100\n",
            "1795/1795 [==============================] - 51s 28ms/step - loss: 0.9892 - accuracy: 0.6336 - val_loss: 0.9118 - val_accuracy: 0.6250\n",
            "Epoch 7/100\n",
            "1795/1795 [==============================] - 51s 28ms/step - loss: 0.9782 - accuracy: 0.6423 - val_loss: 1.2048 - val_accuracy: 0.6250\n",
            "Epoch 8/100\n",
            "1795/1795 [==============================] - 51s 28ms/step - loss: 0.9721 - accuracy: 0.6442 - val_loss: 1.0005 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "1795/1795 [==============================] - 50s 28ms/step - loss: 0.9577 - accuracy: 0.6463 - val_loss: 1.1525 - val_accuracy: 0.6250\n",
            "Epoch 10/100\n",
            "1795/1795 [==============================] - 50s 28ms/step - loss: 0.9597 - accuracy: 0.6495 - val_loss: 0.9969 - val_accuracy: 0.6250\n",
            "Epoch 11/100\n",
            "1795/1795 [==============================] - 48s 27ms/step - loss: 0.9454 - accuracy: 0.6535 - val_loss: 0.9510 - val_accuracy: 0.6250\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f109622af40>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "yJrGVkbM5ibn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e06c95-d095-4686-da58-21bb3c88b1a6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7178/7178 [==============================] - 33s 5ms/step - loss: 1.0255 - accuracy: 0.6145\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0255069732666016, 0.61451655626297]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import sys\n",
        "# import dlib"
      ],
      "metadata": {
        "id": "4vrthn1X5id5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cap = cv2.VideoCapture(0)\n",
        "\n",
        "# if not cap.isOpened():\n",
        "#   print('camera open failed')\n",
        "#   sys.exit()\n",
        "\n",
        "# while True:\n",
        "#   ret, frame = cap.read()\n",
        "#   if not ret:\n",
        "#     print('frame read failed')\n",
        "#     sys.exit()\n",
        "\n",
        "#   face_detector = dlib.cnn_face_detection_model_v1('/content/drive/MyDrive/Colab Notebooks/opencv_project/mmod_human_face_detector.dat')\n",
        "\n",
        "#   face_detection = face_detector(frame, 1)\n",
        "\n",
        "#   left, top, right, bottom = face_detection[0].rect.left(), face_detection[0].rect.top(), face_detection[0].rect.right(), face_detection[0].rect.bottom()\n",
        "\n",
        "#   frame = frame[top:bottom, left:right]\n",
        "\n",
        "#   cv2_imshow(frame)"
      ],
      "metadata": {
        "id": "V46ouv6j5if4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m9ejq57UQq8D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}